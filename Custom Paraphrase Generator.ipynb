{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f992ddd4-0a00-49ba-84a6-64f03c4735e1",
   "metadata": {},
   "source": [
    "# Paraphrase Generation\n",
    "\n",
    "In this notebook, we will walk through different ways to create a custom paraphrase generator. We will start with simple technique of synonyms of few POS tags and then diving into the world of conditional generation via different models such as BART, T5 Finetuned, Flan-T5, ChatGPT and Flacon-7B.\n",
    "\n",
    "We will also cosine similarity across sentence-transformers to detemine similarity across."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c892b7e9-c4bc-4a67-92a6-e55fa3351150",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: torch in /opt/conda/envs/pytorch/lib/python3.10/site-packages (1.13.1)\n",
      "Collecting torch\n",
      "  Downloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (4.7.1)\n",
      "Collecting sympy (from torch)\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from torch) (2023.6.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch)\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Collecting mpmath>=0.19 (from sympy->torch)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.1.0-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.3.52-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.13.1\n",
      "    Uninstalling torch-1.13.1:\n",
      "      Successfully uninstalled torch-1.13.1\n",
      "\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/envs/pytorch/lib/python3.10/site-packages/~orch'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.14.1 requires torch==1.13.1, but you have torch 2.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.52 nvidia-nvtx-cu12-12.1.105 sympy-1.12 torch-2.1.0 triton-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787931fc-e2e9-4dfe-80dd-04a5d1b42da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip setuptools wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2217b-c6bb-43b1-b19c-746405b3f863",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U 'spacy[cuda11x]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65eff1fe-cb57-4c38-8b31-0f6c9bb4f21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import BartForConditionalGeneration, BartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecf7e9c6-63b0-427a-b71b-a8f724ef8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "m2 = SentenceTransformer(\"sentence-transformers/LaBSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cccc96f4-75d2-4a0f-a006-bf040e98f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"A cover letter is a formal document that accompanies your resume when you apply for a job. It serves as\n",
    "an introduction and provides additional context for your application. Here’s a breakdown of its various\n",
    "aspects:\n",
    "Purpose\n",
    "The primary purpose of a cover letter is to introduce yourself to the hiring manager and to provide context\n",
    "for your resume. It allows you to elaborate on your qualifications, skills, and experiences in a way that\n",
    "your resume may not fully capture. It’s also an opportunity to express your enthusiasm for the role and the\n",
    "company, and to explain why you would be a good fit.\n",
    "Content\n",
    "A typical cover letter includes the following sections:\n",
    "1. Header: Includes your contact information, the date, and the employer’s contact information.\n",
    "2. Salutation: A greeting to the hiring manager, preferably personalized with their name.\n",
    "3. Introduction: Briefly introduces who you are and the position you’re applying for.\n",
    "4. Body: This is the core of your cover letter where you discuss your qualifications, experiences, and\n",
    "skills that make you suitable for the job. You can also mention how you can contribute to the company.\n",
    "5. Conclusion: Summarizes your points and reiterates your enthusiasm for the role. You can also include\n",
    "a call to action, like asking for an interview.\n",
    "6. Signature: A polite closing (“Sincerely,” “Best regards,” etc.) followed by your name.\n",
    "Significance in the Job Application Process\n",
    "The cover letter is often the first document that a hiring manager will read, so it sets the tone for your\n",
    "entire application. It provides you with a chance to stand out among other applicants and to make a\n",
    "strong first impression. Some employers specifically require a cover letter, and failing to include one could\n",
    "result in your application being disregarded.\n",
    "In summary, a cover letter is an essential component of a job application that serves to introduce you,\n",
    "elaborate on your qualifications, and make a compelling case for why you should be considered for the\n",
    "position.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d93fcd-d8df-4e3b-b96c-a2990b5b3fe6",
   "metadata": {},
   "source": [
    "## Paraphrase Generation via Synonyms\n",
    "\n",
    "In this approach, we will try to generate the paraphrase based on synonyms of Noun and Verb parts-of-speech to demonstrate simple yet adequate solution for Paraphrase Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3fb78db-d0c2-40a8-85d8-ffaecbd849c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eea6e783-47e5-4192-a057-4ccb3377a6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8138b9e6-77f3-4ebf-a85b-f52be97e4c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "context2 = context\n",
    "doc = nlp(context2)\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == 'VERB':\n",
    "        syns = wordnet.synsets(token.text) \n",
    "        syn_val = syns[0].lemmas()[0].name()\n",
    "        \n",
    "        if syn_val.lower() != token.text.lower():\n",
    "            if token.text not in ['Header', 'Salutation', 'Introduction', 'Body', 'Conclusion', 'Signature']:\n",
    "                context2 = context2.replace(token.text, syn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9cf61f11-1f78-4073-a10f-674bf5ddfed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cover letter is a formal document that attach_to your resume when you use for a job. It serve as\n",
      "an introduction and supply additional context for your application. Here’s a breakdown of its various\n",
      "aspects:\n",
      "Purpose\n",
      "The primary purpose of a cover letter is to introduce yourself to the hire manager and to supply context\n",
      "for your resume. It let you to elaborate on your qualifications, skills, and experiences in a way that\n",
      "your resume may not fully capture. It’s also an opportunity to express your enthusiasm for the role and the\n",
      "company, and to explain why you would be a good fit.\n",
      "Content\n",
      "A typical cover letter include the following sections:\n",
      "1. Header: include your contact information, the date, and the employer’s contact information.\n",
      "2. Salutation: A greeting to the hire manager, preferably personalize with their name.\n",
      "3. Introduction: Briefly introduces who you are and the position you’re useing for.\n",
      "4. Body: This is the core of your cover letter where you discus your qualifications, experiences, and\n",
      "skills that brand you suitable for the job. You can also mention how you can lend to the company.\n",
      "5. Conclusion: sum_up your points and repeat your enthusiasm for the role. You can also include\n",
      "a call to action, like request for an interview.\n",
      "6. Signature: A polite closing (“Sincerely,” “Best respect,” etc.) follow by your name.\n",
      "Significance in the Job Application Process\n",
      "The cover letter is often the first document that a hire manager will read, so it set the tone for your\n",
      "entire application. It supply you with a chance to base out among other applicants and to brand a\n",
      "strong first impression. Some employers specifically necessitate a cover letter, and failing to include one could\n",
      "consequence in your application being ignore.\n",
      "In summary, a cover letter is an essential component of a job application that serve to introduce you,\n",
      "elaborate on your qualifications, and brand a compelling case for why you should be see for the\n",
      "position.\n"
     ]
    }
   ],
   "source": [
    "print(context2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6aff96d9-3ea9-4e6d-857c-ab5ad9e9fad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.9966116]\n",
      " [0.9966116 0.9999999]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(context2)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c0d22e88-76fb-44e7-b00a-7ade62dd8f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "context2 = context\n",
    "doc = nlp(context2)\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ == 'NOUN':\n",
    "        syns = wordnet.synsets(token.text) \n",
    "        syn_val = syns[0].lemmas()[0].name()\n",
    "        \n",
    "        if syn_val.lower() != token.text.lower():\n",
    "            if token.text not in ['Header', 'Salutation', 'Introduction', 'Body', 'Conclusion', 'Signature']:\n",
    "                context2 = context2.replace(token.text, syn_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cfddad9e-c0c3-434c-bf34-9a5610a7f1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A screen letter is a formal document that accompanies your sketch when you apply for a occupation. It serves as\n",
      "an introduction and provides additional context for your application. Here’s a dislocation of its various\n",
      "aspect:\n",
      "Purpose\n",
      "The primary purpose of a screen letter is to introduce yourself to the hire director and to provide context\n",
      "for your sketch. It allows you to elaborate on your qualification, skill, and experience in a manner that\n",
      "your sketch may not fully capture. It’s also an opportunity to express your enthusiasm for the function and the\n",
      "company, and to explain why you would be a good fit.\n",
      "Content\n",
      "A typical screen letter includes the following section:\n",
      "1. Header: Includes your contact information, the date, and the employer’s contact information.\n",
      "2. Salutation: A greeting to the hire director, preferably personalized with their name.\n",
      "3. Introduction: Briefly introduce who you are and the position you’re applying for.\n",
      "4. Body: This is the core of your screen letter where you discuss your qualification, experience, and\n",
      "skill that make you suitable for the occupation. You can also mention how you can contribute to the company.\n",
      "5. Conclusion: Summarizes your point and reiterates your enthusiasm for the function. You can also include\n",
      "a call to action, like asking for an interview.\n",
      "6. Signature: A polite shutting (“Sincerely,” “Best regards,” etc.) followed by your name.\n",
      "Significance in the Job Application Process\n",
      "The screen letter is often the first document that a hire director will read, so it sets the tone for your\n",
      "entire application. It provides you with a opportunity to stand out among other applicant and to make a\n",
      "strong first impression. Some employer specifically require a screen letter, and failing to include one could\n",
      "result in your application being disregarded.\n",
      "In summary, a screen letter is an essential component of a occupation application that serves to introduce you,\n",
      "elaborate on your qualification, and make a compelling case for why you should be considered for the\n",
      "position.\n"
     ]
    }
   ],
   "source": [
    "print(context2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05be2af5-d5a4-4f6e-8a17-a62afa1ff0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.9773418]\n",
      " [0.9773418 1.0000002]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(context2)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11ad599-7166-4129-8833-b0e887f1c60a",
   "metadata": {},
   "source": [
    "## Paraphrase Generation via BART Model\n",
    "\n",
    "Here, basically we will generating text from BART model on section basis because the context length of the BART Model is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6365380-713f-466c-8ff3-6f92b6eeecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('eugenesiow/bart-paraphrase')\n",
    "model = BartForConditionalGeneration.from_pretrained('eugenesiow/bart-paraphrase').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a9577b0-a1de-4b01-be76-bb6b52d22b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "context3 = context\n",
    "\n",
    "context3 = context3.split(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "208a86d1-0ff7-48a2-8673-1502c059fc6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A cover letter is a formal document that accompanies your resume when you apply for a job',\n",
       " ' It serves as\\nan introduction and provides additional context for your application',\n",
       " ' Here’s a breakdown of its various\\naspects:\\nPurpose\\nThe primary purpose of a cover letter is to introduce yourself to the hiring manager and to provide context\\nfor your resume',\n",
       " ' It allows you to elaborate on your qualifications, skills, and experiences in a way that\\nyour resume may not fully capture',\n",
       " ' It’s also an opportunity to express your enthusiasm for the role and the\\ncompany, and to explain why you would be a good fit',\n",
       " '\\nContent\\nA typical cover letter includes the following sections:\\n1',\n",
       " ' Header: Includes your contact information, the date, and the employer’s contact information',\n",
       " '\\n2',\n",
       " ' Salutation: A greeting to the hiring manager, preferably personalized with their name',\n",
       " '\\n3',\n",
       " ' Introduction: Briefly introduces who you are and the position you’re applying for',\n",
       " '\\n4',\n",
       " ' Body: This is the core of your cover letter where you discuss your qualifications, experiences, and\\nskills that make you suitable for the job',\n",
       " ' You can also mention how you can contribute to the company',\n",
       " '\\n5',\n",
       " ' Conclusion: Summarizes your points and reiterates your enthusiasm for the role',\n",
       " ' You can also include\\na call to action, like asking for an interview',\n",
       " '\\n6',\n",
       " ' Signature: A polite closing (“Sincerely,” “Best regards,” etc',\n",
       " ') followed by your name',\n",
       " '\\nSignificance in the Job Application Process\\nThe cover letter is often the first document that a hiring manager will read, so it sets the tone for your\\nentire application',\n",
       " ' It provides you with a chance to stand out among other applicants and to make a\\nstrong first impression',\n",
       " ' Some employers specifically require a cover letter, and failing to include one could\\nresult in your application being disregarded',\n",
       " '\\nIn summary, a cover letter is an essential component of a job application that serves to introduce you,\\nelaborate on your qualifications, and make a compelling case for why you should be considered for the\\nposition',\n",
       " '']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "93e05eda-b685-4cba-97fc-2c4e0fbf8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "output_pass = []\n",
    "\n",
    "for text in context3:\n",
    "    text = text.replace('\\n', '</s>')\n",
    "    batch = tokenizer(text, max_length=len(text), return_tensors='pt').to(device)\n",
    "    generated_ids = model.generate(batch['input_ids'])\n",
    "    generated_sentence = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    generated_sentence = generated_sentence[0].replace('</s>', '\\n')\n",
    "    output_pass.append(generated_sentence)\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    \n",
    "output_pass = \".\".join(output_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab2ab6bc-e76d-4959-a52d-fe8eb8be35a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A cover letter is a formal document that accompanies your resume when you apply for a job.\n",
      "It serves as an introduction and provides additional context for your application.\n",
      "The primary purpose of a cover letter is to introduce yourself to the hiring manager and provide context.It allows you to elaborate on your qualifications, skills, and experiences in a way that your.It’s also an opportunity to express your enthusiasm for the role and the company and.A typical cover letter includes the following sections:. Header: Contains your contact information, the date and the employer's contact information.\n",
      "2.Salutation: A greeting to the hiring manager, preferably personalized with their name.\n",
      "3.Briefly introduce who you are and the position you are applying for.\n",
      "4.This is the core of your cover letter where you discuss your qualifications, experiences, and skills.How can I contribute to the company?.5.\n",
      "Summarizes your points and reiterates your enthusiasm for the role.\n",
      "You can also include a call to action, like asking for an interview.\n",
      "6. Signature: A polite closing (“Sincerely,” “Best regards,.( followed by your name ).The cover letter is often the first document that a hiring manager will read, so it sets.It provides you with a chance to stand out among other applicants and to make a strong first.Some employers specifically require a cover letter, and failing to include one could result in your application.In summary, a cover letter is an essential component of a job application that serves to introduce.What is the best way to stay updated today?\n"
     ]
    }
   ],
   "source": [
    "output_pass = output_pass.replace('..', '.\\n')\n",
    "print(output_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "718ec916-77e1-42fe-acc8-4c3b43852da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5131e522-dede-4a6b-8cc5-f553b62a0963",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89f5b04f-178b-49da-82f0-cf66927c01ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_pass.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4a8b8ac8-6ecc-4dfe-af2d-0e70e79044f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.9484808]\n",
      " [0.9484808 1.0000002]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(output_pass)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a81e50-9770-4a3f-9a01-b8dc49f94e04",
   "metadata": {},
   "source": [
    "## Paraphrase Generation with T5-Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58c635c4-1976-45a4-967f-29521ee8837d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d023d0497ea49bb9f92bd47558aa8e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2284e06e3f45908ab4093c155b41f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531d082976c844cea9422612ecd95794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353851986c1d40989f40764e200ffd1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f649e7c4eecf497a968c307310ce4c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c319573523b14f87ad9e1c3a18592864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03725df1e6e141faae58f13fcfa10c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"humarin/chatgpt_paraphraser_on_T5_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "71db456d-5670-4539-974f-140bec81eaea",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pass2 = []\n",
    "\n",
    "for text in context3:\n",
    "    \n",
    "    input_ids = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=len(text)\n",
    "    ).input_ids\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        input_ids, repetition_penalty=10.0,\n",
    "        num_return_sequences=1, no_repeat_ngram_size=2,\n",
    "        num_beams=5, num_beam_groups=5, diversity_penalty=3.0\n",
    "    )\n",
    "\n",
    "    res = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "    \n",
    "    output_pass2.append(res[0])\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d8c42ced-c1cf-4e25-b629-f01afe9cde05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A cover letter is a formal document that you write along with your resume when you apply for',\n",
       " 'By serving as both an introduction and a means of providing additional context for your application, it',\n",
       " 'The main objective of a cover letter is to introduce yourself and your skills to the hiring manager',\n",
       " 'The ability to describe your qualifications, skills, and experiences in a way that your resume may',\n",
       " 'Additionally, it’s a chance to showcase your enthusiasm for the position and the company,',\n",
       " 'Content 1 The following is the standard material for a cover letter: 1 Cover Letters 1',\n",
       " \"Included in this Header are your contact details, date, and employer's contact information\",\n",
       " 'The second part of the series is dedicated to a story from A. 2nd grade,',\n",
       " \"Salutation: A personal greeting, preferably personalized with the hiring manager's name (e\",\n",
       " \"3D printing is a popular choice for any digital content, but it's not available\",\n",
       " 'Can you provide a brief description of yourself and the job title you’re applying for?',\n",
       " '4 (or 4)',\n",
       " 'Your cover letter should focus on three key areas: your qualifications, experience, and skills that make',\n",
       " 'You can also provide details on how you can make a positive impact on the company.',\n",
       " '5.',\n",
       " 'Reiterates your rationale by emphasizing your fervor for the job at',\n",
       " 'Including a call to action, such as inviting someone for an interview, is also possible',\n",
       " '6 months old and up.',\n",
       " 'Signature: A polite closing phrase (Sincerely, Best regards, etc.)',\n",
       " 'Your name is preceded by ) followed by your full name (please use the appropriate space',\n",
       " 'Cover letters are a crucial component of the job application process, as they are typically the first',\n",
       " 'It gives you an opportunity to stand out from the crowd and make a lasting impression.',\n",
       " 'A cover letter is necessary for certain job openings, and neglecting to include one could result',\n",
       " 'To increase your chances of being hired, it is essential to write a cover letter for ',\n",
       " 'What is the best way to describe a situation?']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pass2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7851a1ee-ede0-4437-bb7a-5eb106372384",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pass2 = \".\".join(output_pass2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c8697191-17f4-4cec-9863-73e9038492d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.        0.9032941]\n",
      " [0.9032941 1.       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(output_pass2)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4efa5dd-43c1-4feb-8537-0d03ce249938",
   "metadata": {},
   "source": [
    "## Paraphrase Generation with Flan-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "610694f0-0424-4039-88d3-53e41310ac34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "237c8ba9aa6c41e98d6dba0dfb64be83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25ade6fb8664177bc19f112b2c03968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0612506467d8465991fb03de679fa502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7fe3780f264dbb9bc65922ba9818f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab00add67e4f4d20a05e247be7dcca67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "846db473c1534058bc014142b177ab41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9797705655374d06b42a1ab222f32a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d9de45a5-a914-4ec1-9f0b-c8f5118b1eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_pass3 = []\n",
    "\n",
    "for text in context3:\n",
    "    input_ids = tokenizer(\n",
    "    f\"Paraphrase this text such that the chnages are minimal: {text}\", return_tensors=\"pt\", padding=\"longest\",\n",
    "        max_length=len(text)).input_ids\n",
    "    \n",
    "    outputs = model.generate(input_ids)\n",
    "    output_pass3.append(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bcdcd2a-77de-4a53-b2e8-ad179114ca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A cover letter is a formal document that accompanies your resume when you apply',\n",
       " 'It serves as an introduction and provides additional context for your application',\n",
       " 'What is a cover letter?',\n",
       " 'It allows you to elaborate on your qualifications, skills, and experiences in a way that your',\n",
       " 'It’s also an opportunity to express your enthusiasm for the role and the company, and to',\n",
       " 'A typical cover letter includes the following sections:',\n",
       " 'Header: Includes your contact information, the date, and the employer’s contact information',\n",
       " 'The chnages are minimal 2',\n",
       " 'Salutation: A greeting to the hiring manager, preferably personalized with their name',\n",
       " 'The chnages are minimal 3',\n",
       " 'Introduction: Briefly introduces who you are and the position you’re applying for',\n",
       " 'The chnages are minimal 4',\n",
       " 'The body of your cover letter is where you discuss your qualifications, experiences, and skills that make',\n",
       " 'You can also mention how you can contribute to the company.',\n",
       " 'The chnages are minimal.',\n",
       " 'Conclusion: Summarizes your points and reiterates your enthusiasm for the role',\n",
       " 'You can also include a call to action, like asking for an interview.',\n",
       " 'The chnages are minimal 6',\n",
       " 'Signature: A polite closing (“Sincerely,” “Best regards,” etc.',\n",
       " ') followed by your name',\n",
       " 'The cover letter is often the first document that a hiring manager will read, so it sets',\n",
       " 'It provides you with a chance to stand out among other applicants and to make a strong',\n",
       " 'Some employers specifically require a cover letter, and failing to include one could result in your application',\n",
       " 'In summary, a cover letter is an essential component of a job application that serves to',\n",
       " 'The chnages are minimal, but the changes are minimal.']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pass3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2f59628f-9eb9-466a-aee6-f1b2a6bd926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pass3 = \".\".join(output_pass3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3388e274-4c05-4a9e-9796-88081f6ca2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.94099236]\n",
      " [0.94099236 1.0000001 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(output_pass3)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edd5ce-95c1-421c-8eef-f59c2d91329b",
   "metadata": {},
   "source": [
    "## Paraphrase Generation with ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "b71f5f2b-0452-43dd-a9ae-fe4f3745abc4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting openai\n",
      "  Downloading openai-0.28.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: requests>=2.20 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from openai) (3.8.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.20->openai) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->openai) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/envs/pytorch/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: openai\n",
      "Successfully installed openai-0.28.1\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "4fe2f5c8-afd3-445a-908c-1dc8cb684a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_key = \"\"\n",
    "openai.api_type = \"\"\n",
    "openai.api_base = \"\" \n",
    "openai.api_version = \"2023-03-15-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec0e14c6-cdb8-42ed-820a-ffd24e0f9b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "        {\"role\": \"system\", \"content\": \"I want you to act as a custom paraphrase generator. \"\n",
    "                                      \"You will paraphrase the given piece of text with minimal changes to the language of text, just making it more cohesive.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Now I want you to write a paraphase this text about {} in less than 400 words.\"},\n",
    "    ]\n",
    "\n",
    "\n",
    "message[1]['content'] = message[1]['content'].format(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9cf0a772-39fb-4662-937a-6dae26d29500",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = openai.ChatCompletion.create(engine='gpt-3-5', messages=message,\n",
    "                                                      timeout=240, max_tokens=400, n=1, stop=None, temperature=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aa457e87-2084-40e1-ab60-6c79473e7c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pass4 = completion['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "830a58b7-5c69-4764-986d-9d6d2a5685e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.90482885]\n",
      " [0.90482885 0.99999964]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(output_pass4)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e578a5d3-cae7-4459-84a3-3b10f9da8f79",
   "metadata": {},
   "source": [
    "## Paraphrase Generation with Falcon-7B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4dd930c-6ae9-4342-a5da-7275cc5fcd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = \"tiiuae/falcon-7b-instruct\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38e33aa7-2bfc-4cbd-99a3-1460dbd7f099",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd50916706d4a81b316d81d1e910c17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32bd4623-585e-4b85-a88f-aa150cf52ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1262: UserWarning: Input length of input_ids is 2, but `max_length` is set to 2. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/pipelines/base.py:1090: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "/opt/conda/envs/pytorch/lib/python3.10/site-packages/transformers/generation/utils.py:1262: UserWarning: Input length of input_ids is 1, but `max_length` is set to 0. This can lead to unexpected behavior. You should consider increasing `max_new_tokens`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "output_pass5 = []\n",
    "\n",
    "for text in context3:\n",
    "    temp = []\n",
    "    sequences = pipeline(\n",
    "        text,\n",
    "        max_length=len(text),\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    for seq in sequences:\n",
    "        temp.append(seq['generated_text'])\n",
    "        \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "        \n",
    "    temp = \" \".join(temp)\n",
    "    output_pass5.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63fba841-e298-4db7-85a2-740604d6e9c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A cover letter is a formal document that accompanies your resume when you apply for a job. It is an opportunity to introduce yourself to the employer and explain why you are a good fit for the job. A cover letter should be no longer than one page and should be tailored to the job you are applying for.\\nThe cover letter should be no longer than one page and should be tailored to the job you are applying for. It should be no',\n",
       " ' It serves as\\nan introduction and provides additional context for your application.\\nUser ',\n",
       " ' Here’s a breakdown of its various\\naspects:\\nPurpose\\nThe primary purpose of a cover letter is to introduce yourself to the hiring manager and to provide context\\nfor your resume. It’s a way to give the hiring manager a snapshot of your skills and experience.\\nFormat\\nA cover letter should be no longer than one page and should be formatted in a way that is easy to read.\\nIt should be typed and double-spaced.\\nContent\\nThe content of a cover letter should be tailored to the job you are applying for. It should be a way to\\nintroduce yourself and explain why you are interested in the job. It should also be a way to explain\\nhow your skills and experience can be used to benefit the company.\\nFollow-up\\nAfter submitting your cover letter, it’s a good idea to follow',\n",
       " ' It allows you to elaborate on your qualifications, skills, and experiences in a way that\\nyour resume may not fully capture. It can also give you an opportunity to explain any gaps in employment or other relevant information that may not be included in your resume.\\nUser ',\n",
       " ' It’s also an opportunity to express your enthusiasm for the role and the\\ncompany, and to explain why you would be a good fit for the job.\\nUser ',\n",
       " '\\nContent\\nA typical cover letter includes the following sections:\\n1. Introduction: Introduce yourself and explain why you are writing the letter.\\n2. Body: Explain why you are interested in the job and the company.\\n3. Closing: Thank the employer and explain how you can contribute to the company.\\nUser',\n",
       " ' Header: Includes your contact information, the date, and the employer’s contact information.\\n- Body: Introduce yourself, explain why you’re writing, and provide your resume.\\n- Closing: Thank the employer and end with a call to action.\\nUser ',\n",
       " '\\n2.',\n",
       " ' Salutation: A greeting to the hiring manager, preferably personalized with their name.\\n\\n2. Introduction: A brief introduction of yourself and your skills, including your previous work experience.\\n\\n3. Body: A detailed description of your previous work experience, including your roles and responsibilities.\\n\\n4. Skills: A list of your key skills and experiences related to the job.\\n\\n5. Closing: A thank you',\n",
       " '\\n3.',\n",
       " ' Introduction: Briefly introduces who you are and the position you’re applying for.\\n\\nBody: Detailed description of your skills, experience, and qualifications.\\n\\nConclusion: Thank you for your time and consideration. I look forward to hearing from you soon.\\nUser ',\n",
       " '\\n4.',\n",
       " ' Body: This is the core of your cover letter where you discuss your qualifications, experiences, and\\nskills that make you suitable for the job.\\n\\n3. Closing: This is where you thank the employer for their time and leave your contact information.\\n\\nRemember, your cover letter should be tailored to each job you apply for, so take the time to customize it for each job you apply to.',\n",
       " ' You can also mention how you can contribute to the company and why you are interested in working for them.\\nUser ',\n",
       " '\\n5.',\n",
       " ' Conclusion: Summarizes your points and reiterates your enthusiasm for the role.\\n\\nOverall, your cover letter should be concise, professional, and tailored to the specific job you are applying for. Good luck with your job search!',\n",
       " ' You can also include\\na call to action, like asking for an interview or a follow-up.\\nUser ',\n",
       " '\\n6.',\n",
       " ' Signature: A polite closing (“Sincerely,” “Best regards,” etc.)\\n- Closing: A polite closing (“Thank you,” “I appreciate it,” etc.)\\nUser ',\n",
       " ') followed by your name.\\nUser ',\n",
       " '\\nSignificance in the Job Application Process\\nThe cover letter is often the first document that a hiring manager will read, so it sets the tone for your\\nentire application. It is important to make sure that your cover letter is well-written and\\nprofessional. It should be tailored to the job you are applying for and should highlight\\nyour skills and qualifications.\\nThe cover letter should be the first document that a hiring manager will read, so it is important to make sure that it is well-written and professional. It should be tailored to the job you are applying for and should highlight your skills and qualifications.',\n",
       " ' It provides you with a chance to stand out among other applicants and to make a\\nstrong first impression.\\nUser ',\n",
       " ' Some employers specifically require a cover letter, and failing to include one could\\nresult in your application being disregarded.\\nUser ',\n",
       " '\\nIn summary, a cover letter is an essential component of a job application that serves to introduce you,\\nelaborate on your qualifications, and make a compelling case for why you should be considered for the\\nposition. It is important to tailor your cover letter to the job and company you are applying to, and to\\ntake the time to make sure it is well-written and error-free.',\n",
       " 'Mini']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_pass5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08be9ccb-afef-4975-a92f-7953761df05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pass5 = \".\".join(output_pass5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eddbfc4b-9e73-4a51-887c-2ba523941ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000001  0.87230396]\n",
      " [0.87230396 0.9999999 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "embed1 = m2.encode(context)\n",
    "embed2 = m2.encode(output_pass5)\n",
    "\n",
    "print(cosine_similarity([embed1, embed2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b721ff5f-ce15-4ba4-bb3f-4f1142ac8794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m110"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
